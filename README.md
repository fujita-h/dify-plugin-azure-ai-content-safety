![Icon](./_assets/03390-icon-service-Content-Safety.svg)

# Azure AI Content Safety

[![GitHub Repo](https://img.shields.io/badge/GitHub_Repo-fujita--h/dify--plugin--azure--ai--content--safety-blue?logo=github)](https://github.com/fujita-h/dify-plugin-azure-ai-content-safety)  
[![GitHub Release](https://img.shields.io/github/v/release/fujita-h/dify-plugin-azure-ai-content-safety)](https://github.com/fujita-h/dify-plugin-azure-ai-content-safety/releases)
[![GitHub License](https://img.shields.io/github/license/fujita-h/dify-plugin-azure-ai-content-safety)](https://github.com/fujita-h/dify-plugin-azure-ai-content-safety/blob/main/LICENSE)


This Plugion provides a set of tools to enhance the safety of generative AI applications with advanced guardrails for responsible AI.
Azure AI Content Safety is an AI service that detects harmful user-generated and AI-generated content in applications and services.

## Tools provided by this plugin

### Text Moderation

Scans text for sexual content, violence, hate, and self harm with multi-severity levels.

Learn more abount the text moderation categories [here](https://learn.microsoft.com/ja-jp/azure/ai-services/content-safety/concepts/harm-categories?tabs=warning).


### Image Moderation

Scans text for sexual content, violence, hate, and self harm with multi-severity levels.

Learn more abount the text moderation categories [here](https://learn.microsoft.com/ja-jp/azure/ai-services/content-safety/concepts/harm-categories?tabs=warning).

### Prompt Shields

Prompt Shields analyzes LLM input and detects adversarial user input attacks.

Learn more abount the prompt shields [here](https://learn.microsoft.com/azure/ai-services/content-safety/concepts/jailbreak-detection).

## Configuration and Usage

See [Plugin README](./README.difypkg.md) for configuration and usage details.

## Notes

### Supported languages

See the [official documentation](https://learn.microsoft.com/azure/ai-services/content-safety/language-support) for the supported languages.


## Contributing

This plugin is open-source and contributions are welcome. Please visit the GitHub repository to contribute.
